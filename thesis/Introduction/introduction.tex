\chapter{Introduction}
Statistical analysis and inference of multivariate phenomena might be performed in the context of probabilistic graphical models that provides a natural framework for developing complicated structures where the graph of the model defines the conditional dependence between random variables. On the other hand -- this is naturally enforced in Markov random fields which by definition satisfy Markov property. Strict connection between Markov random fields and graphical models that factorizes enables us to view energy based models, a fundamental class of probability distributions extensively used in statistical physics, in the framework of graphical models.

A particular example of undirected graphical model is Boltzmann machine -- structure that has been extensively investigated over last $30$ years as it can be seen as a natural approximator of any probabilistic disitribution. A special example from this family is restricted Boltzmann machine -- an undirected neural network that doesn't have connections between neighbour nodes. It is believed that one of the main reasons of the resurgence of deep architectures is the effective unsupervised pre-training of those structures with restricted Boltzmann machines. The advances in training deep neural networks over couple last years allowed us to train very powerful statistical model which yields substantial improvements in many areas of machine learning like speech or vision recognition, image processing or machine translation. 


It has been shown empirically that unsupervised pre-training of deep structures ..
\cite{erhan2010does}

A new algorithm - deterministic - previous didn't work.\cite{gabrie2015training}

The thesis is organized as follows. In chapter $1$ I will show strict mapping between Markov random fields and energy based models and embed Boltzman Machine in to the framework of probabilistic graphical models. known as Markov random fields which enables us to obtain many theoretical results and well-developed algorithms
A detailed derivation is shown in Appendix A.

Chapter $2$ describes the experimental toy framework used to evaluate the performance of the extended mean field approximation 

In chapter $3$ I describes  replicate main results from the Gabri\'e et al. paper 


introduces describes

Chapter 4
