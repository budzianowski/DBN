\chapter{Introduction}
The resurgence of deep neural architectures over couple last years allowed us to train very powerful statistical model which yields substantial improvements in many areas of machine learning like speech or vision recognition, image processing or machine translation. One of the main reasons for the resurgence of deep architectures is przypisany to the effective unsupervised pre-training of those structures with restricted Boltzmann machines (RBMs) -- a special case of general energy-based model where there aren't connections between nodes from the same layer. 


It has been shown empirically that unsupervised pre-training of deep structures ..
\cite{erhan2010does}

A new algorithm - deterministic - previous didn't work.

Chapter 1
We will start by embedding BMs in to the framework of probabilistic graphical models known as Markov random fields which enables us to obtain many theoretical results and well-developed algorithms

Chapter 2

Chapter 3
