\relax 
\abx@aux@sortscheme{nty}
\abx@aux@cite{tieleman2008training}
\abx@aux@cite{robbins1951stochastic}
\abx@aux@cite{bottou1998online}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.1}Unsupervised learning}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.2}Training of Boltzmann Machines}{1}}
\newlabel{eq:sgd}{{3}{1}}
\newlabel{eq:sgd@cref}{{[equation][3][]3}{1}}
\newlabel{eq:loglikelihood}{{4}{1}}
\newlabel{eq:loglikelihood@cref}{{[equation][4][]4}{1}}
\newlabel{eq:gradient}{{5}{1}}
\newlabel{eq:gradient@cref}{{[equation][5][]5}{1}}
\abx@aux@cite{hinton2002training}
\abx@aux@cite{fischer2012introduction}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.3}Monte Carlo methods}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.3.1}Markov chain Monte Carlo}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.3.2}Gibbs sampling}{2}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.4}Contrastive Divergence}{2}}
\newlabel{eq:gradientCD}{{6}{2}}
\newlabel{eq:gradientCD@cref}{{[equation][6][]6}{2}}
\abx@aux@cite{neal1992connectionist}
\abx@aux@cite{besag1972nearest}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 1}}{3}}
\newlabel{fig:gibbsSampling}{{1}{3}}
\newlabel{fig:gibbsSampling@cref}{{[figure][1][]1}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {0.4.1}Persistent contrastive divergence}{3}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.5}Learning using extended mean field approximation}{3}}
\newlabel{eq:emfLL}{{7}{3}}
\newlabel{eq:emfLL@cref}{{[equation][7][]7}{3}}
\abx@aux@cite{lecun1998}
\abx@aux@cite{gabrie2015training}
\abx@aux@cite{salakhutdinov2008learning}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.6}Approximating the log-likelihood}{4}}
\newlabel{eq:pseudoLL}{{12}{4}}
\newlabel{eq:pseudoLL@cref}{{[equation][12][]12}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.7}Real scale model -- MNIST data set}{4}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {0.8}Comparison of both approaches}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 1}}{5}}
\newlabel{fig:validLL}{{2}{5}}
\newlabel{fig:validLL@cref}{{[figure][2][]2}{5}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 1}}{6}}
\newlabel{fig:PvalidLL}{{3}{6}}
\newlabel{fig:PvalidLL@cref}{{[figure][3][]3}{6}}
